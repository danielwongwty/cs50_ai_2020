# Demo

Here we demonstrate the calling of the functions we've implemented and make  
sure they behave the same as what required in the specifications. You may try  
to call `doctest` module for a fast check.

Let's import the `pagerank` module first before testing them.

    >>> from pagerank import *

-----

## `transition_model(corpus, page, damping_factor)`

It returns a dictionary representing the probability distribution over which  
page a random surfer would visit next, given a corpus of pages, a current  
page, and a damping factor. This function has the following specifications:

1. The returned value should be a dict with one key for each page in the  
   corpus, and its value be the corresponding probability to be chosen. All  
   of the values should sum to `1`.

2. An example is given in the instruction and expected return is provided as  
   an illustration.

3. If `page` has no outgoing links, this function should return an equal  
   probability distribution among all pages including the `page` itself.

Let's use the example given in point 2 for checking the first 2 specifications:

    >>> corpus = {
    ...     "1.html": {"2.html", "3.html"}, 
    ...     "2.html": {"3.html"}, 
    ...     "3.html": {"2.html"}
    ... }
    >>> page = "1.html"
    >>> damping_factor = 0.85
    >>> rtn = transition_model(corpus, page, damping_factor)
    >>> set(rtn.keys()) == set(corpus.keys())                       # Spec. 1a
    True
    >>> sum(rtn.values()) == 1.0                                    # Spec. 1b
    True
    >>> expected = {"1.html": 0.05, "2.html": 0.475, "3.html": 0.475}
    >>> any(not(abs(rtn[p] - expected[p]) < 0.001) for p in corpus) # Spec. 2
    False

Let's create a case to check point 3:

    >>> corpus = {"1.html": {"2.html"}, "2.html": {}}

In which "2.html" has no outgoing link. We choose "2.html" as our current page.

    >>> page = "2.html"

It is expected that the probability distribution returned should be 50/50.

    >>> rtn = transition_model(corpus, page, damping_factor)
    >>> expected = {"1.html": 0.5, "2.html": 0.5}
    >>> any(not(abs(rtn[p] - expected[p]) < 0.001) for p in corpus)
    False

## `sample_pagerank(corpus, damping_factor, n)`

It finds the estimated PageRank of the given `corpus` by sampling. Here are  
the specifications:

1. The returned value should be a dict with one key for each page in the  
   corpus, and its value be the corresponding probability to be chosen. All  
   of the values should sum to `1`.

2. `n` is the number of samples, which should be at least `1`. The first  
   sample should be generated by choosing from a page at random.

3. For each of the remaining samples, the next sample should be generated from  
   the previous sample based on the previous sample's transition model.

Let's check point 1 here:

    >>> corpus = crawl("corpus0")
    >>> rtn = sample_pagerank(corpus, 0.85, 10000)
    >>> set(rtn.keys()) == set(corpus.keys())                       # Spec. 1a
    True
    >>> sum(rtn.values()) == 1.0                                    # Spec. 1b
    True

For point 2 and 3, it's apparently impossible to prove by running simple test.  
We can however compare the result with `iterate_pagerank()` and see if they are  
very close numerically.

## `iterate_pagerank(corpus, damping_factor)`

It finds the PageRank of the given `corpus` by calculating an iteration  
formula under the result is accurate to within `0.001`. Here are the  
specifications:

1. The returned value should be a dict with one key for each page in the  
   corpus, and its value be the corresponding probability to be chosen. All  
   of the values should sum to `1`.

2. The function should begin by assigning each page a rank of `1 / N`, where  
   `N` is the total number of pages in the corpus.

3. The function should then repeatedly calculate new rank values based on all  
   of the current rank values until no PageRank value changes by more than  
   `0.001` between the current rank values and the new rank values.

Let's check point 1 here:

    >>> corpus = crawl("corpus0")
    >>> rtn = iterate_pagerank(corpus, 0.85)
    >>> set(rtn.keys()) == set(corpus.keys())                       # Spec. 1a
    True
    >>> sum(rtn.values()) == 1.0                                    # Spec. 1b
    True

For point 2 and 3, it's apparently impossible to prove by running simple test.  
We can however compare the result with `sample_pagerank()` and see if they are  
very close numerically.

## Iteration Test

As some specifications above are hard to check by running simple case. I've  
instead implemented another 2 methods (`test_ranks()` and `print_rank_table()`)  
for checking if both algorithms could return very closed results.

By running the test with different values, I've found that when `samples` tends  
to be large, the results of `sample_pagerank()` and `iterate_pagerank()` tends  
to be close.

A sample call is shown below:

    >>> corpus = crawl("corpus1")
    >>> test_ranks(corpus, samples=10000, iteration=10, max_error=0.02)  
    Loop..........
    Finish a 10-iteration pagerank comparison with 10000 samples

Meaning that we have compared the result between `sample_pagerank(n=10000)` and  
`iterate_pagerank()` for 10 times and the difference of  
corresponding probability of pages are within the given maximum absolute error  
of `0.02`.
